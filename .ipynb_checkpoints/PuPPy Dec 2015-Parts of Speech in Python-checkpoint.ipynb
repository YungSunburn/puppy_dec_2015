{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "First, let's analyze some text...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# “Each of us is full of shit in our own special way. We are all shitty little snowflakes dancing in the universe.” \n",
    "― Lewis Black, Me of Little Faith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/don.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alice's Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/plus.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Taggers/Parsers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Tagging and Parsing into Trees is different:\n",
    "\n",
    "* Tagging: Tagging every word [fast]\n",
    "* Parsing: Tagging and puts into Tree [slow]\n",
    "* Chunking: Gives pieces of Trees [medium]\n",
    "* POSH Rules:  *Special* fact and deap and context aware [amazing]\n",
    "\n",
    "Other important *words*:\n",
    "\n",
    "* Probabilistic Parsing\n",
    "* Chart Parsing\n",
    "    * Grammer\n",
    "    * Strategy\n",
    "\n",
    "*NLTK is the mother of all mother of NLP*\n",
    "\n",
    "so many parsers:\n",
    "\n",
    "* pyStatParser (python yay!, little slow, but fun)\n",
    "* Stanford (popular) and btw, online! => http://nlp.stanford.edu:8080/parser/\n",
    "* TextBlob (python yay! NLTK simplification)\n",
    "* clips Pattern (python yay!)\n",
    "* MaltParser (java 1.8)\n",
    "* spaCy (pyython yay!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Parsers/Taggers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = \"Each of us is full of shit in our own special way\"\n",
    "\n",
    "# setup display for demo\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['DISPLAY'] = 'localhost:1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pyStatParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from stat_parser import Parser\n",
    "parser = Parser()\n",
    "parser.parse(sent)\n",
    "tree = parser.parse(sent) # returns nltk Tree instance\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "blob = TextBlob(sent)\n",
    "blob.parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaltParser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "mp = nltk.parse.malt.MaltParser(os.getcwd(),\n",
    "                                model_filename=\"engmalt.linear-1.7.mco\")\n",
    "mp.parse_one(sent.split()).tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pattern.en import parse, pprint\n",
    "\n",
    "s = parse(sent,\n",
    "     tokenize = True,  # Tokenize the input, i.e. split punctuation from words.\n",
    "         tags = True,  # Find part-of-speech tags.\n",
    "       chunks = True,  # Find chunk tags, e.g. \"the black cat\" = NP = noun phrase.\n",
    "    relations = True,  # Find relations between chunks.\n",
    "      lemmata = True,  # Find word lemmata.\n",
    "        light = False) \n",
    "pprint(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from spacy.en import English\n",
    "parser = English()\n",
    "parsedData = parser(unicode(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, token in enumerate(parsedData):\n",
    "    print(\"original:\", token.orth, token.orth_)\n",
    "    print(\"lowercased:\", token.lower, token.lower_)\n",
    "    print(\"lemma:\", token.lemma, token.lemma_)\n",
    "    print(\"shape:\", token.shape, token.shape_)\n",
    "    print(\"prefix:\", token.prefix, token.prefix_)\n",
    "    print(\"suffix:\", token.suffix, token.suffix_)\n",
    "    print(\"log probability:\", token.prob)\n",
    "    print(\"Brown cluster id:\", token.cluster)\n",
    "    print(\"----------------------------------------\")\n",
    "    if i > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://api.spacy.io/displacy/index.html?full=Each of us is full of shit in our own special way. We are all shitty little snowflakes dancing in the universe.\" target=\"_new\">Interactive Example</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Word Langauge Graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from visualize_word_graph import draw_graph  \n",
    "draw_graph(\"dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "draw_graph(\"noise\", hypernym=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Alice's Yelp Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_sounds =['The sound in the place is terrible.',\n",
    "            'dining with clatter and the occasional smell of BMW exausts',\n",
    "            'Also, the acoustics are not conducive to having any sort of conversation.']\n",
    "not_bad_sounds = [\"not to sound like a snob\",\n",
    "                  \"at your table and you can tune the sound to whichever game you're interested in\",\n",
    "                  \"oh god I sound old!\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. parts of speach for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pattern.en import parse, pprint\n",
    "\n",
    "def print_parts(sents):\n",
    "    for sent in sents:\n",
    "        s = parse(sent,\n",
    "             tokenize = True,  # Tokenize the input, i.e. split punctuation from words.\n",
    "                 tags = True,  # Find part-of-speech tags.\n",
    "               chunks = True,  # Find chunk tags, e.g. \"the black cat\" = NP = noun phrase.\n",
    "            relations = True,  # Find relations between chunks.\n",
    "              lemmata = True,  # Find word lemmata.\n",
    "                light = False) \n",
    "        print sent\n",
    "        pprint(s)\n",
    "sents = bad_sounds + not_bad_sounds\n",
    "print_parts(bad_sounds + not_bad_sounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penn Treebank Project Chunks <a href=\"tagguide.pdf\">guide</a>\n",
    "\n",
    "#### parts\n",
    "\n",
    "<table class=\"border\">\n",
    "<tbody>\n",
    "<tr>\n",
    "<td><span class=\"smallcaps\">Tag </span></td>\n",
    "<td><span class=\"smallcaps\">Description </span></td>\n",
    "<td class=\"smallcaps\">Example</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">CC </span></td>\n",
    "<td>conjunction, coordinating</td>\n",
    "<td><em>and, or, but</em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">CD </span></td>\n",
    "<td>cardinal number</td>\n",
    "<td><em>five, three, 13%</em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">DT </span></td>\n",
    "<td>determiner</td>\n",
    "<td><em>the, a, these <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">EX </span></td>\n",
    "<td>existential there</td>\n",
    "<td><em><span style=\"text-decoration: underline;\">there</span> were six boys <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">FW </span></td>\n",
    "<td>foreign word</td>\n",
    "<td><em>mais <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">IN </span></td>\n",
    "<td>conjunction, subordinating or preposition</td>\n",
    "<td><em>of, on, before, unless <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">JJ </span></td>\n",
    "<td>adjective</td>\n",
    "<td><em>nice, easy </em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">JJR </span></td>\n",
    "<td>adjective, comparative</td>\n",
    "<td><em>nicer, easier</em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">JJS </span></td>\n",
    "<td>adjective, superlative</td>\n",
    "<td><em>nicest, easiest <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">LS </span></td>\n",
    "<td>list item marker</td>\n",
    "<td><em>&nbsp;</em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">MD </span></td>\n",
    "<td>verb, modal auxillary</td>\n",
    "<td><em>may, should <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">NN </span></td>\n",
    "<td>noun, singular or mass</td>\n",
    "<td><em>tiger, chair, laughter <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">NNS </span></td>\n",
    "<td>noun, plural</td>\n",
    "<td><em>tigers, chairs, insects <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">NNP </span></td>\n",
    "<td>noun, proper singular</td>\n",
    "<td><em>Germany, God, Alice <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">NNPS </span></td>\n",
    "<td>noun, proper plural</td>\n",
    "<td><em>we met two <span style=\"text-decoration: underline;\">Christmases</span> ago <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">PDT </span></td>\n",
    "<td>predeterminer</td>\n",
    "<td><em><span style=\"text-decoration: underline;\">both</span> his children <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">POS</span></td>\n",
    "<td>possessive ending</td>\n",
    "<td><em>'s</em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">PRP </span></td>\n",
    "<td>pronoun, personal</td>\n",
    "<td><em>me, you, it <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">PRP&#36; </span></td>\n",
    "<td>pronoun, possessive</td>\n",
    "<td><em>my, your, our <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">RB </span></td>\n",
    "<td>adverb</td>\n",
    "<td><em>extremely, loudly, hard&nbsp; <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">RBR </span></td>\n",
    "<td>adverb, comparative</td>\n",
    "<td><em>better <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">RBS </span></td>\n",
    "<td>adverb, superlative</td>\n",
    "<td><em>best <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">RP </span></td>\n",
    "<td>adverb, particle</td>\n",
    "<td><em>about, off, up <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">SYM </span></td>\n",
    "<td>symbol</td>\n",
    "<td><em>&#37; <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">TO </span></td>\n",
    "<td>infinitival to</td>\n",
    "<td><em>what <span style=\"text-decoration: underline;\">to</span> do? <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">UH </span></td>\n",
    "<td>interjection</td>\n",
    "<td><em>oh, oops, gosh <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">VB </span></td>\n",
    "<td>verb, base form</td>\n",
    "<td><em>think <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">VBZ </span></td>\n",
    "<td>verb, 3rd person singular present</td>\n",
    "<td><em>she <span style=\"text-decoration: underline;\">thinks </span><br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">VBP </span></td>\n",
    "<td>verb, non-3rd person singular present</td>\n",
    "<td><em>I <span style=\"text-decoration: underline;\">think </span><br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">VBD </span></td>\n",
    "<td>verb, past tense</td>\n",
    "<td><em>they <span style=\"text-decoration: underline;\">thought </span><br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">VBN </span></td>\n",
    "<td>verb, past participle</td>\n",
    "<td><em>a <span style=\"text-decoration: underline;\">sunken</span> ship <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">VBG </span></td>\n",
    "<td>verb, gerund or present participle</td>\n",
    "<td><em><span style=\"text-decoration: underline;\">thinking</span> is fun <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">WDT </span></td>\n",
    "<td><em>wh</em>-determiner</td>\n",
    "<td><em>which, whatever, whichever <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">WP </span></td>\n",
    "<td><em>wh</em>-pronoun, personal</td>\n",
    "<td><em>what, who, whom <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">WP$$</span></td>\n",
    "<td><em>wh</em>-pronoun, possessive</td>\n",
    "<td><em>whose, whosever <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">WRB</span></td>\n",
    "<td><em>wh</em>-adverb</td>\n",
    "<td><em>where, when <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">. </span></td>\n",
    "<td>punctuation mark, sentence closer</td>\n",
    "<td><em>.;?* <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">, </span></td>\n",
    "<td>punctuation mark, comma</td>\n",
    "<td><em>, <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">: </span></td>\n",
    "<td>punctuation mark, colon</td>\n",
    "<td><em>: <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">( </span></td>\n",
    "<td>contextual separator, left paren</td>\n",
    "<td><em>( <br></em></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">) </span></td>\n",
    "<td>contextual separator, right paren</td>\n",
    "<td><em>) <br></em></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "#### chunks\n",
    "\n",
    "<table class=\"border\">\n",
    "<tbody>\n",
    "<tr>\n",
    "<td><span class=\"smallcaps\">Tag </span></td>\n",
    "<td><span class=\"smallcaps\">Description </span></td>\n",
    "<td><span class=\"smallcaps\">Words </span></td>\n",
    "<td><span class=\"smallcaps\">Example </span></td>\n",
    "<td align=\"right\">%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">NP </span></td>\n",
    "<td>noun phrase<span class=\"postag\">&nbsp;</span></td>\n",
    "<td><span class=\"postag\">DT</span>+<span class=\"postag\">RB</span>+<span class=\"postag\">JJ</span>+<span class=\"postag\">NN</span> + <span class=\"postag\">PR</span></td>\n",
    "<td><em>the strange bird</em></td>\n",
    "<td align=\"right\">&nbsp;51</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">PP </span></td>\n",
    "<td>prepositional phrase</td>\n",
    "<td><span class=\"postag\">TO</span>+<span class=\"postag\">IN </span></td>\n",
    "<td><em>in between</em></td>\n",
    "<td align=\"right\">&nbsp;19</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">VP&nbsp; </span></td>\n",
    "<td>verb phrase&nbsp;</td>\n",
    "<td><span class=\"postag\">RB</span>+<span class=\"postag\">MD</span>+<span class=\"postag\">VB&nbsp; </span></td>\n",
    "<td><em>was looking<br></em></td>\n",
    "<td align=\"right\">9</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">ADVP</span></td>\n",
    "<td>adverb phrase</td>\n",
    "<td><span class=\"postag\">RB</span></td>\n",
    "<td><em>also<br></em></td>\n",
    "<td align=\"right\">&nbsp;6</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">ADJP</span></td>\n",
    "<td>adjective phrase<span class=\"postag\">&nbsp;</span></td>\n",
    "<td><span class=\"postag\">CC</span>+<span class=\"postag\">RB</span>+<span class=\"postag\">JJ</span></td>\n",
    "<td><em>warm and cosy</em></td>\n",
    "<td align=\"right\">&nbsp;3</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">SBAR</span></td>\n",
    "<td>subordinating conjunction&nbsp;</td>\n",
    "<td><span class=\"postag\">IN</span></td>\n",
    "<td><em><span style=\"text-decoration: underline;\">whether</span> or not<br></em></td>\n",
    "<td align=\"right\">3</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">PRT </span></td>\n",
    "<td>particle</td>\n",
    "<td><span class=\"postag\">RP</span></td>\n",
    "<td><em><span style=\"text-decoration: underline;\">up</span> the stairs</em></td>\n",
    "<td align=\"right\">&nbsp;1</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span class=\"postag\">INTJ</span></td>\n",
    "<td>interjection</td>\n",
    "<td><span class=\"postag\">UH</span></td>\n",
    "<td><em>hello</em><em><br></em></td>\n",
    "<td align=\"right\">&nbsp;0</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. seach for patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pattern.en import parsetree\n",
    "from pattern.search import search\n",
    "\n",
    "for sent in sents:\n",
    "    t = parsetree(sent)\n",
    "    print \n",
    "    print sent\n",
    "    print \"Tagged Sent:\", t\n",
    "    print \"Verbs:\", search('VB*', t) # verbs\n",
    "    print \"ADJP:\", search('ADJP', t) # verbs   \n",
    "    print \"Nouns:\", search('NN', t) # all nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. create similar word list (stemming + synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from pattern.en import parsetree\n",
    "from pattern.search import taxonomy, WordNetClassifier, search\n",
    "\n",
    "taxonomy.classifiers.append(WordNetClassifier())\n",
    "\n",
    "def get_parts(word, pos, recursive=False):\n",
    "    parts = [word, ]\n",
    "    parts += taxonomy.children(word, pos=pos, recursive=recursive)\n",
    "    parts += taxonomy.parents(word, pos=pos, recursive=recursive)\n",
    "    return parts\n",
    "\n",
    "def word_search(t, word, pos):\n",
    "    parts = get_parts(word, pos)\n",
    "    results = search(pos, t)\n",
    "    for result in results:\n",
    "        #  print result.string, parts\n",
    "        if any(x in result.string.split() for x in parts):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def run_a_rule(sent, word, pos):\n",
    "    t = parsetree(sent)\n",
    "    return word_search(t, word, pos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"1. 'sound' is a NN\"\n",
    "print run_a_rule(sents[0], 'noise', 'NN')\n",
    "\n",
    "print \"2. clatter is a NN\"\n",
    "print run_a_rule(sents[1], 'noise', 'NN')\n",
    "\n",
    "print \"3. acoustics is NNS and RB Not\"\n",
    "print run_a_rule(sents[2], 'acoustics', 'NNS') and run_a_rule(sents[2], 'not', 'RB')\n",
    "\n",
    "print \"4. sound is a VB\"\n",
    "print run_a_rule(sents[3], 'noise', 'VB*') \n",
    "\n",
    "print \"5. Sounds is JJ\"\n",
    "print run_a_rule(sents[4], 'sound', 'JJ') \n",
    "\n",
    "print \"6. sound is VBP\"\n",
    "print run_a_rule(sents[5], 'noise', 'VB*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. create a feature extractor function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ext_func(tgt):\n",
    "    return bool(not (run_a_rule(tgt, 'noise', 'VB*') and not run_a_rule(tgt, 'sound', 'JJ'))\n",
    "                and (run_a_rule(tgt, 'noise', 'NN') or run_a_rule(tgt, 'acoustics', 'NNS') or\n",
    "                        (run_a_rule(tgt, 'acoustics', 'NNS') and run_a_rule(tgt, 'not', 'RB'))))\n",
    "        \n",
    "print \"bad noises in review:\"\n",
    "for sent in bad_sounds:\n",
    "    print \"\\t\" + sent\n",
    "    assert(ext_func(sent) == True)\n",
    "print\n",
    "print \"no mention of bad noises:\"\n",
    "for sent in not_bad_sounds:\n",
    "    print \"\\t\" + sent\n",
    "    assert(ext_func(sent) == False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pickle\n",
    "from lxml import etree\n",
    "from StringIO import StringIO\n",
    "\n",
    "zf = zipfile.ZipFile('nhtsa_as_xml.zip', 'r')\n",
    "nhtsa_injured = zf.read('nhtsa_injured.xml')\n",
    "nhtsa_not_injured = zf.read('nhtsa_not_injured.xml')\n",
    "xml_injured = etree.parse(StringIO(nhtsa_injured))\n",
    "xml_not_injured = etree.parse(StringIO(nhtsa_not_injured))\n",
    "\n",
    "\n",
    "def injured(l):\n",
    "    return ['0' != str(x) and 'injured' or 'notinjured' for x in l]\n",
    "\n",
    "\n",
    "def data(x):\n",
    "    out = [x.xpath(\"//rows/row/@c1\"),\n",
    "           injured(x.xpath(\"//rows/row/@c8\")),\n",
    "           x.xpath(\"//rows/row/@c2\")]\n",
    "    return list(reversed(zip(*out)))\n",
    "\n",
    "\n",
    "xml_injured_data = data(xml_injured)[:800]\n",
    "xml_not_injured_data = data(xml_not_injured)[:800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('106859',\n",
       " 'injured',\n",
       " 'VIOLENT DEPLOYMENT OF AIR BAG DURING COLLISION, CAUSING INJURIES TO CONSUMERS (BURNS ON HANDS AND ARMS).')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_injured_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\"seamless=\"seamless\" src=\"https://plot.ly/~brianray/6.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from visualize_word_graph import draw_graph  \n",
    "draw_graph(\"injury\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 900 instances, test on 700 instances\n",
      "accuracy: 0.168571428571\n",
      "Most Informative Features\n",
      "                    BAGS = True           injure : not    =     19.1 : 1.0\n",
      "               INSURANCE = True           injure : not    =     18.0 : 1.0\n",
      "                  DEPLOY = True           injure : not    =     17.4 : 1.0\n",
      "                    NECK = True           injure : not    =     15.3 : 1.0\n",
      "                 TOTALED = True           injure : not    =     15.3 : 1.0\n",
      "                 AIRBAGS = True           injure : not    =     13.2 : 1.0\n",
      "                INJURIES = True           injure : not    =     12.9 : 1.0\n",
      "                  POLICE = True           injure : not    =     10.9 : 1.0\n",
      "                     2ND = True           injure : not    =     10.0 : 1.0\n",
      "                    2014 = True           injure : not    =     10.0 : 1.0\n",
      "                 INSPECT = True           injure : not    =     10.0 : 1.0\n",
      "                DEPLOYED = True           injure : not    =      9.4 : 1.0\n",
      "                 CRASHED = True           injure : not    =      9.1 : 1.0\n",
      "                 COVERED = True              not : injure =      8.8 : 1.0\n",
      "                FEBRUARY = True           injure : not    =      8.7 : 1.0\n",
      "                    TYPE = True           injure : not    =      8.7 : 1.0\n",
      "                    SITE = True           injure : not    =      8.7 : 1.0\n",
      "                SUFFERED = True           injure : not    =      7.6 : 1.0\n",
      "                OPPOSITE = True           injure : not    =      7.3 : 1.0\n",
      "               DIRECTION = True           injure : not    =      7.3 : 1.0\n",
      "                 ARRIVED = True           injure : not    =      7.3 : 1.0\n",
      "                    HEAD = True           injure : not    =      7.3 : 1.0\n",
      "                  IMPACT = True           injure : not    =      6.9 : 1.0\n",
      "                INVOLVED = True           injure : not    =      6.6 : 1.0\n",
      "                  HANDLE = True           injure : not    =      6.6 : 1.0\n",
      "                  POPPED = True           injure : not    =      6.0 : 1.0\n",
      "               SHOULDER, = True           injure : not    =      6.0 : 1.0\n",
      "               PREMATURE = True           injure : not    =      6.0 : 1.0\n",
      "                 ENTERED = True           injure : not    =      6.0 : 1.0\n",
      "                  DEMAND = True           injure : not    =      6.0 : 1.0\n",
      "                ELECTRIC = True           injure : not    =      6.0 : 1.0\n",
      "                  ACCESS = True           injure : not    =      6.0 : 1.0\n",
      "               DESTROYED = True           injure : not    =      6.0 : 1.0\n",
      "               COLLISION = True           injure : not    =      6.0 : 1.0\n",
      "                  ROLLED = True           injure : not    =      6.0 : 1.0\n",
      "                KNOCKING = True           injure : not    =      6.0 : 1.0\n",
      "                  EXISTS = True           injure : not    =      6.0 : 1.0\n",
      "                 DESPITE = True           injure : not    =      6.0 : 1.0\n",
      "               VEHICLE'S = True           injure : not    =      6.0 : 1.0\n",
      "                 HANDLES = True           injure : not    =      6.0 : 1.0\n",
      "                    LOT, = True           injure : not    =      6.0 : 1.0\n",
      "                   FILED = True           injure : not    =      5.8 : 1.0\n",
      "                  REPORT = True           injure : not    =      5.6 : 1.0\n",
      "                 DEALER, = True              not : injure =      5.5 : 1.0\n",
      "                     *AK = True           injure : not    =      5.3 : 1.0\n",
      "         rule(SUSTAINED) = True           injure : not    =      5.3 : 1.0\n",
      "                  WANTED = True           injure : not    =      5.2 : 1.0\n",
      "                DECEMBER = True           injure : not    =      5.2 : 1.0\n",
      "                SEVERELY = True           injure : not    =      5.2 : 1.0\n",
      "               AUTOMATIC = True           injure : not    =      5.2 : 1.0\n",
      "             ILLUMINATED = True              not : injure =      5.1 : 1.0\n",
      "                     AGO = True              not : injure =      4.9 : 1.0\n",
      "                 HYUNDAI = True              not : injure =      4.8 : 1.0\n",
      "               CONTACT'S = True           injure : not    =      4.7 : 1.0\n",
      "                       D = True           injure : not    =      4.7 : 1.0\n",
      "               ACCIDENT, = True           injure : not    =      4.7 : 1.0\n",
      "                SOLENOID = True           injure : not    =      4.7 : 1.0\n",
      "                      11 = True           injure : not    =      4.7 : 1.0\n",
      "                 FAILED, = True           injure : not    =      4.7 : 1.0\n",
      "                   SIDE, = True           injure : not    =      4.7 : 1.0\n",
      "                FOLLOWED = True           injure : not    =      4.7 : 1.0\n",
      "                   OLDER = True           injure : not    =      4.7 : 1.0\n",
      "                      V6 = True           injure : not    =      4.7 : 1.0\n",
      "                  LOCATE = True           injure : not    =      4.7 : 1.0\n",
      "                 DEFECTS = True           injure : not    =      4.7 : 1.0\n",
      "                 ROADWAY = True           injure : not    =      4.7 : 1.0\n",
      "                 FEELING = True           injure : not    =      4.7 : 1.0\n",
      "                  SIENNA = True           injure : not    =      4.7 : 1.0\n",
      "                   PAINT = True           injure : not    =      4.7 : 1.0\n",
      "                     US, = True           injure : not    =      4.7 : 1.0\n",
      "                   SEAT, = True           injure : not    =      4.7 : 1.0\n",
      "              CONFIDENCE = True           injure : not    =      4.7 : 1.0\n",
      "                     AAA = True           injure : not    =      4.7 : 1.0\n",
      "                CONCERN, = True           injure : not    =      4.7 : 1.0\n",
      "                 WHEELS, = True           injure : not    =      4.7 : 1.0\n",
      "            CATASTROPHIC = True           injure : not    =      4.7 : 1.0\n",
      "                REMEMBER = True           injure : not    =      4.7 : 1.0\n",
      "                    WONT = True           injure : not    =      4.7 : 1.0\n",
      "                   CASE, = True           injure : not    =      4.7 : 1.0\n",
      "                 DEALING = True           injure : not    =      4.7 : 1.0\n",
      "                MANIFOLD = True           injure : not    =      4.7 : 1.0\n",
      "              DIFFERENCE = True           injure : not    =      4.7 : 1.0\n",
      "                  IMPALA = True           injure : not    =      4.7 : 1.0\n",
      "                  PICKUP = True           injure : not    =      4.7 : 1.0\n",
      "                   CAR'S = True           injure : not    =      4.7 : 1.0\n",
      "                   FACE, = True           injure : not    =      4.7 : 1.0\n",
      "                 PARKED, = True           injure : not    =      4.7 : 1.0\n",
      "                INFINITI = True           injure : not    =      4.7 : 1.0\n",
      "                 SLAMMED = True           injure : not    =      4.7 : 1.0\n",
      "                    GATE = True           injure : not    =      4.7 : 1.0\n",
      "              RESOLUTION = True           injure : not    =      4.7 : 1.0\n",
      "               CORRECTED = True              not : injure =      4.5 : 1.0\n",
      "            UNEXPECTEDLY = True           injure : not    =      4.4 : 1.0\n",
      "                   LEAVE = True           injure : not    =      4.4 : 1.0\n",
      "               CONVERTER = True           injure : not    =      4.4 : 1.0\n",
      "               CONTACT�S = True           injure : not    =      4.4 : 1.0\n",
      "               BASICALLY = True           injure : not    =      4.4 : 1.0\n",
      "                   BACK, = True           injure : not    =      4.4 : 1.0\n",
      "                    NONE = True           injure : not    =      4.3 : 1.0\n",
      "                  BUMPER = True           injure : not    =      4.3 : 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'injure'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from pattern.search import taxonomy, search\n",
    "\n",
    "taxonomy.append('dislocated', type='injury')\n",
    "taxonomy.append('sustained', type='injury')\n",
    "taxonomy.append('burn', type='injury')\n",
    "taxonomy.append('injury', type='hurt')\n",
    "\n",
    "\n",
    "def check_sustained(text):\n",
    "    if len(search('HURT', text)) > 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def feats(text):\n",
    "    words = text.replace(\".\", \"\").split()\n",
    "    out = dict([(word, True) for word in words])\n",
    "    if 'SUSTAINED' in out:\n",
    "        del out['SUSTAINED']\n",
    "    out['rule(SUSTAINED)'] = check_sustained(text)\n",
    "    return out\n",
    "    \n",
    "negcutoff = len(xml_not_injured_data)*3/4\n",
    "poscutoff = len(xml_injured_data)*3/4\n",
    " \n",
    "not_inj_data = xml_not_injured_data[:negcutoff] + xml_injured_data[:poscutoff]\n",
    "inj_data = xml_not_injured_data[negcutoff:] + xml_injured_data[poscutoff:]    \n",
    "    \n",
    "negfeats = [(feats(f[2]), 'not') for f in not_inj_data]\n",
    "posfeats = [(feats(f[2]), 'injure') for f in inj_data]\n",
    "egcutoff = len(negfeats)*3/4\n",
    "poscutoff = len(posfeats)*3/4\n",
    " \n",
    "trainfeats = negfeats[:negcutoff] + posfeats[:poscutoff]\n",
    "testfeats = negfeats[negcutoff:] + posfeats[poscutoff:]\n",
    "print 'train on %d instances, test on %d instances' % (len(trainfeats), len(testfeats))\n",
    " \n",
    "classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "print 'accuracy:', nltk.classify.util.accuracy(classifier, testfeats)\n",
    "classifier.show_most_informative_features(n=100)\n",
    "\n",
    "\n",
    "classifier.classify(feats(\"HE SUSTAINED INJURY\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POSH Syntax Overview "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converts:\n",
    "\n",
    "    return bool(not (run_a_rule(tgt, 'noise', 'VB*') and not run_a_rule(tgt, 'sound', 'JJ'))\n",
    "                and (run_a_rule(tgt, 'noise', 'NN') or run_a_rule(tgt, 'acoustics', 'NNS') or\n",
    "                        (run_a_rule(tgt, 'acoustics', 'NNS') and run_a_rule(tgt, 'not', 'RB'))))\n",
    "\n",
    "To:\n",
    "\n",
    "    SENT: !VB*(noise+3) and !JJ(sound+3) ) and (NN(noise+2) | NNS(acoustics) | (NNS(acoustics) & RB(not)))\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POSH Library \n",
    "\n",
    "Comming soon to: https://github.com/brianray/posh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/me.png\">\n",
    "### About Me\n",
    "\n",
    "\n",
    "* Deloitte Enterprise Science brray (at) deloitte  dot com\n",
    "* ChiPy (Chicago Python User Group) brianhray@gmail.com\n",
    "* LinkedIn: https://www.linkedin.com/in/brianray\n",
    "* Twitter: <a href=\"https://twitter.com/brianray\" class=\"twitter-follow-button\" data-show-count=\"false\" data-size=\"large\">Follow @brianray</a>\n",
    "<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Copy of this presentation found here: https://github.com/brianray/puppy_dec_2015"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
